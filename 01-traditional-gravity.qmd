---
bibliography: 00-references.bib
---

# Partial equilibrium trade policy analysis with structural gravity

## Traditional gravity estimates

### Preparing the data

If the reader has never used R before, please check chapters 1 to 25 from @wickham2016r.

If the reader has only fitted a few regressions in R, without much practice on transforming and cleaning data before, please check chapters 5 and 18 from @wickham2016r.

Please see the note from page 42 in @yotov2016advanced. It is a really important note, which tells us that we need to:

1. Filter observations for a range of years (1986, 1990, 1994, 1998, 2002 and 2006)
2. Transform some variables to logarithm scale (trade and dist) and create new variables from those in the original dataset
3. Remove cases where both the exporter and the importer are the same
4. Drop observations where the trade flow is zero

Unlike @yotov2016advanced, here we shall use a single dataset for all the applications and subset its columns depending on what we need. This decision kept the *tradepolicy* R package as light as possible.

Before conducting any data filtering or regression, we need to load the required packages.

```{r ch1_app_1_packages}
#| message: false
#| warning: false

# dataset and summary functions
library(tradepolicy)

# data transformation
library(dplyr)
library(tidyr)

# regression
library(capybara)

# delta method
library(msm)
```

Step 1, including subsetting columns for this application, is straightforward.

```{r ch1_app_1_data_1}
ch1_application1 <- agtpa_applications %>%
  select(exporter, importer, pair_id, year, trade, dist, cntg, lang, clny) %>%
  filter(year %in% seq(1986, 2006, 4))
```

For step 2, this can be divided in parts, starting with the log transformation of trade and distance.

```{r ch1_app_1_data_2}
ch1_application1 <- ch1_application1 %>%
  mutate(
    log_trade = log(trade),
    log_dist = log(dist)
  )
```

Continuing step 2, we can now create the variables $Y_{i,t}$ and $E_{i,t}$ that appear on the OLS model equation in the book.

```{r ch1_app_1_data_3}
ch1_application1 <- ch1_application1 %>%
  # Create Yit
  group_by(exporter, year) %>%
  mutate(
    y = sum(trade),
    log_y = log(y)
  ) %>%
  # Create Eit
  group_by(importer, year) %>%
  mutate(
    e = sum(trade),
    log_e = log(e)
  )
```

The OLS model with remoteness index needs both exporter and importer index, which grouping variables can create. We divide it into sub-steps: Replicate the computation of total exports, then the remoteness index for exporters, and finally the total imports with the corresponding remoteness index for importers.

```{r ch1_app_1_data_4}
ch1_application1 <- ch1_application1 %>%
  # Replicate total_e
  group_by(exporter, year) %>%
  mutate(total_e = sum(e)) %>%
  group_by(year) %>%
  mutate(total_e = max(total_e)) %>%
  # Replicate rem_exp
  group_by(exporter, year) %>%
  mutate(
    remoteness_exp = sum(dist * total_e / e),
    log_remoteness_exp = log(remoteness_exp)
  ) %>%
  # Replicate total_y
  group_by(importer, year) %>%
  mutate(total_y = sum(y)) %>%
  group_by(year) %>%
  mutate(total_y = max(total_y)) %>%
  # Replicate rem_imp
  group_by(importer, year) %>%
  mutate(
    remoteness_imp = sum(dist / (y / total_y)),
    log_remoteness_imp = log(remoteness_imp)
  ) %>%
  ungroup()
```

To create the variables for the OLS with Fixed Effects Model, we followed box #1 on page 44 from @yotov2016advanced. We combine both exporter and importer variables with the year to create the fixed effects variables.

```{r ch1_app_1_data_5}
ch1_application1 <- ch1_application1 %>%
  # This merges the columns exporter/importer with year
  mutate(
    exp_year = paste0(exporter, year),
    imp_year = paste0(importer, year)
  )
```

The addition of exporter/importer time fixed effects concludes step 2, and now we need to perform step 3. This step will
be commented for now as I found an error in the reported $R^2$ for the PPML model that I show next.

```{r ch1_app_1_data_6}
# ch1_application1 <- ch1_application1 %>%
#   filter(exporter != importer)
```

Some cases require conducting step 4, and we will be explicit about it when needed.

### OLS estimation ignoring multilateral resistance terms

The general equation for this model is
$$
\begin{align}
\log X_{ij,t} =& \:\beta_0 + \beta_1 DIST_{i,j} + \beta_2 CNTG_{i,j} + \beta_3 LANG_{i,j} + \beta_4 CLNY_{i,j} + \beta_5 \log Y_{i,t} +\\
\text{ }& \:\beta_6 \log E_{j,t} + \varepsilon_{ij,t}.
\end{align}
$$

Please see page 41 in @yotov2016advanced for full detail of each variable.

The model for this case is straightforward, and in this case, we need to apply step 4 from the previous section to drop cases where the trade is zero.

```{r ch1_app_1_ols_1}
fit_ols <- felm(
  log_trade ~ log_dist + cntg + lang + clny + log_y + log_e,
  data = ch1_application1 %>%
    filter(trade > 0) %>%
    filter(exporter != importer) # commented out step 3
)

fit_ols
```

Note that the $R^2$ and adjusted $R^2$ look the same because of rounding.

```{r ch1_app_1_ols_2}
fit_ols$r_squared
fit_ols$adj_r_squared
```

The employed function, `felm()`, does not carry a copy of its training data by default besides providing faster fitting for models with fixed effects. This is not the case in base R, where `glm()` outputs include this data, increasing the model's size, but this does not affect the model's predictions and can be changed as the user needs it [@trimmingfat].

The model is almost ready. We only need to stick to the methodology from @yotov2016advanced and cluster the standard errors by country pair (see the note on page 42, it is imperative).

The capybara package processes formulas as:

```r
response ~ slopes | fixed_effects | cluster
```

The model with clustered standard errors is as follows.

```{r ch1_app_1_ols_3}
fit_ols <- felm(
  log_trade ~ log_dist + cntg + lang + clny + log_y + log_e | 0 | pair_id,
  data = ch1_application1 %>%
    filter(trade > 0) %>%
    filter(exporter != importer) # commented out step 3
)

fit_ols
```

To conduct the RESET test we need to add the squared fitted values to the training data.

```{r ch1_app_1_ols_4}
ch1_application1_ols <- ch1_application1 %>%
  filter(
    trade > 0,
    exporter != importer
  )

ch1_application1_ols <- ch1_application1_ols %>%
  mutate(trade_hat_sq = (predict(fit_ols, newdata = ch1_application1_ols))^2)

reset_ols <- felm(
  log_trade ~ log_dist + cntg + lang + clny + log_y + log_e + trade_hat_sq | 0 | pair_id,
  data = ch1_application1_ols
)

round(reset_ols$coef_table["trade_hat_sq", "Pr(>|z|)"], 4)
```

### OLS estimation controlling for multilateral resistance terms with remote indexes

The remoteness model adds variables to the OLS model. The general equation for this model is
$$
\begin{align}
\log X_{ij,t} =& \:\beta_0 + \beta_1 DIST_{i,j} + \beta_2 CNTG_{i,j} + \beta_3 LANG_{i,j} + \beta_4 CLNY_{i,j} + \beta_5 \log Y_{i,t} +\\
\text{ }& \beta_6 \log E_{j,t} + \beta_7 \log(REM\_EXP_i,t) + \beta_8 \log(REM\_IMP_i,t) + \varepsilon_{ij,t}.
\end{align}
$$

In the equation above $REM\_EXP$ and $REM\_IMP$ are defined as
$$
\begin{align}
\log(REM\_EXP_{i,t}) &= \log \left( \sum_j \frac{DIST_{i,j}}{E_{j,t} / Y_t} \right) \text{ and }\\
\log(REM\_IMP_{j,t}) &= \log \left( \sum_i \frac{DIST_{i,j}}{Y_{i,t} / Y_t} \right).
\end{align}
$$

Please see page 43 in @yotov2016advanced for full detail of each variable.

Our approach follows box #1 on page 43 from @yotov2016advanced. Fitting the regression is straightforward. It is just about adding more regressors to what we did in the last section, and we can create a list with a summary for the model.

```{r ch1_app_1_ols_remoteness_1}
fit_ols_remoteness <- felm(
  log_trade ~ log_dist + cntg + lang + clny + log_y + log_e +
    log_remoteness_exp + log_remoteness_imp | 0 | pair_id,
  data = ch1_application1 %>%
    filter(trade > 0) %>%
    filter(exporter != importer) # commented out step 3
)

fit_ols_remoteness
```

For the RESET test, we need to add the squared fitted values to the training data as before.

```{r ch1_app_1_ols_remoteness_2}
ch1_application1_ols_remoteness <- ch1_application1 %>%
  ungroup() %>%
  filter(
    trade > 0,
    exporter != importer
  )

ch1_application1_ols_remoteness <- ch1_application1_ols_remoteness %>%
  mutate(trade_hat_sq = (predict(fit_ols_remoteness, newdata = ch1_application1_ols_remoteness))^2) 

reset_ols_remoteness <- felm(
  log_trade ~ log_dist + cntg + lang + clny + log_y + log_e +
    log_remoteness_exp + log_remoteness_imp + trade_hat_sq | 0 | pair_id,
  data = ch1_application1_ols_remoteness
)

round(reset_ols_remoteness$coef_table["trade_hat_sq", "Pr(>|z|)"], 4)
```

### OLS estimation controlling for multilateral resistance terms with fixed effects

The general equation for this model is
$$
\begin{align}
\log X_{ij,t} =& \: \beta_1 \log(DIST)_{i,j} + \beta_2 CNTG_{i,j} + \beta_3 LANG_{i,j} +\\
\text{ }& \:\beta_4 CLNY_{i,j} + \pi_{i,t} + \chi_{i,t} + \varepsilon_{ij,t}.
\end{align}
$$

Where the added terms, concerning the OLS model, are $\pi_{i,t}$ and $\chi_{i,t}$ that account for exporter-time and importer-time fixed effects, respectively. See page 44 in @yotov2016advanced for full detail of each variable.

We can quickly generate a list as we did with the previous models. The only difference to the previous models is that in this case that the variables to the right of the "|" operator are the fixed effects, which are treated differently by the *fixest* package, which is used internally by the *tradepolicy* package, for faster model fitting.

Please notice that the summaries intentionally do not show fixed effects, because there are cases where we have thousands of fixed effects.

```{r ch1_app_1_fe_1}
# tp_summary_app_1(
#   formula = log_trade ~ log_dist + cntg + lang + clny | exp_year + imp_year,
#   data = filter(ch1_application1, trade > 0),
#   method = "ols"
# )

fit_fe <- felm(
  log_trade ~ log_dist + cntg + lang + clny | exp_year + imp_year | pair_id,
  data = ch1_application1 %>%
    filter(trade > 0) %>%
    filter(exporter != importer) # commented out step 3
)

fit_fe
```

Note that the `felm()` function does not print the fixed effects. You can access them with `fit_fe$fixed_effects` and
`fit_fe$fe_levels` as needed.

For the RESET test, we need to add the squared fitted values to the training data as before.

```{r ch1_app_1_fe_2}
ch1_application1_fe <- ch1_application1 %>%
  ungroup() %>%
  filter(
    trade > 0,
    exporter != importer
  )

ch1_application1_fe <- ch1_application1_fe %>%
  mutate(trade_hat_sq = (predict(fit_fe, newdata = ch1_application1_fe))^2)

reset_fe <- felm(
  log_trade ~ log_dist + cntg + lang + clny + trade_hat_sq | exp_year + imp_year | pair_id,
  data = ch1_application1_fe
)

round(reset_fe$coef_table["trade_hat_sq", "Pr(>|z|)"], 4)
```

### PPML estimation controlling for multilateral resistance terms with fixed effects

The general equation for this model is
$$
\begin{align}
X_{ij,t} =& \:\exp\left[\beta_1 \log(DIST)_{i,j} + \beta_2 CNTG_{i,j} +\right.\\
\text{ }& \:\left.\beta_3 LANG_{i,j} + \beta_4 CLNY_{i,j} + \pi_{i,t} + \chi_{i,t}\right] \times \varepsilon_{ij,t}.
\end{align}
$$

The reason to compute this model, despite the lower speed compared to OLS, is that PPML is the only estimator perfectly consistent with the theoretical gravity model. By estimating with PPML, the fixed effects correspond precisely to the corresponding theoretical terms.

The data for this model is the same as for the fixed effects model, and one option in R is to use the `fepois()` function.

```{r ch1_app_1_ppml_1, eval = FALSE}
fit_ppml <- fepoisson(trade ~ log_dist + cntg + lang + clny | exp_year + imp_year | pair_id,
  data = ch1_application1 %>%
    filter(exporter != importer) # commented out step 3
)

fit_ppml
```

Up to this part, everything matches table 1 in @yotov2016advanced, except for the $R^2$ of the PPML model, which I could
not replicate except by obtaining an out-of-sample $R^2$ by obtaining the fitted values including domestic flows. I
believe there is a mistake in the book regarding this value.

```{r ch1_app_1_ppml_2}
trade <- pull(ch1_application1, trade)
trade_hat <- predict(fit_ppml, type = "response", newdata = ch1_application1)
cor(trade, trade_hat)^2
```

For the RESET test, we need to add the squared fitted values to the training data as before.

```{r ch1_app_1_ppml_3}
ch1_application1_ppml <- ch1_application1 %>%
  ungroup() %>%
  filter(exporter != importer)

ch1_application1_ppml <- ch1_application1_ppml %>%
  mutate(trade_hat_sq = (predict(fit_ppml, newdata = ch1_application1_ppml))^2)

reset_ppml <- fepoisson(
  trade ~ log_dist + cntg + lang + clny + trade_hat_sq | exp_year + imp_year | pair_id,
  data = ch1_application1_ppml
)

round(reset_ppml$coef_table["trade_hat_sq", "Pr(>|z|)"], 4)
```

### Presenting all models together

Capybara provides the `summary_table()` function to present multiple models together. We can use it to show all the
models fitted in this section (note it is a general use function that does not include the RESET test p-values).

```{r ch1_app_1_summary_table}
summary_table(fit_ols, fit_ols_remoteness, fit_fe, fit_ppml)
```

The difference with @yotov2016advanced is that the 3rd and 4th columns do not include the "grand mean" (intercept)
because I included exporter-time and importer-time fixed effects, which remove the need for an intercept as it is
absorbed by the fixed effects and the slopes and their standard effect match.

## The "distance puzzle" resolved

### Preparing the data

Please see the note from page 47 in @yotov2016advanced. We need to proceed with similar steps as in the previous section.

The distance puzzle proposes the gravity specification
$$
\begin{align}
X_{ij,t} =& \:\exp\left[\pi_{i,t} + \chi_{i,t} + \beta_1 \log(DIST)_{i,j} + \beta_2 CNTG_{i,j} + \beta_3 LANG_{i,j}\right]\times\\
\text{ }& \:\exp\left[\beta_4 CLNY_{i,j} + \beta_5 \log(DIST\_INTRA_{i,i})\right] \times \varepsilon_{ij,t}.
\end{align}
$$

The difference concerning the last section is that now we need to separate the distance variable into multiple columns that account for discrete-time effects. The $\beta_T$ terms of the equation reflect this. Perhaps the easiest option is to transform the year into a text column and then use the `pivot_wider()` function.

We need to remove cases where the exporter is the same as the importer and cases where trade is zero for the OLS model. For the PPML models, we need to mark rows where the exporter and the importer are the same, and we need to create the same country column, which is also required to transform the distance variables as shown in box #1 in page 48 from @yotov2016advanced.

In order to avoid creating two very similar datasets, we shall create one dataset to cover both OLS and PPML.

```{r ch1_app_2_data_1}
ch1_application2 <- agtpa_applications %>%
  select(exporter, importer, pair_id, year, trade, dist, cntg, lang, clny) %>%
  # this filter covers both OLS and PPML
  filter(year %in% seq(1986, 2006, 4)) %>%
  mutate(
    # variables for both OLS and PPML
    exp_year = paste0(exporter, year),
    imp_year = paste0(importer, year),
    year = paste0("log_dist_", year),
    log_trade = log(trade),
    log_dist = log(dist),
    smctry = ifelse(importer != exporter, 0, 1),

    # PPML specific variables
    log_dist_intra = log_dist * smctry,
    intra_pair = ifelse(exporter == importer, exporter, "inter")
  ) %>%
  pivot_wider(names_from = year, values_from = log_dist, values_fill = 0) %>%
  mutate(across(log_dist_1986:log_dist_2006, function(x) x * (1 - smctry)))
```

The `across()` function is a shortcut to avoid repetition, as in the following example provided for reference without
computation.

```{r ch1_app_2_data_3, eval = FALSE}
ch1_application2 %>%
  mutate(
    log_dist_1986 =  log_dist_1986 * (1 - smctry),
    log_dist_1990 =  log_dist_1990 * (1 - smctry),

    # repeat log_dist_T many_times for T = 1994, 1998, ...

    log_dist_2006 =  log_dist_2006 * (1 - smctry)
  )
```

Note that the OLS model shall require filtering when we specify the model because we skipped filtering the cases where trade is equal to zero and both the importer and the exporter are the same. Because the solution for the "distance puzzle" implies different transformations and filters for the OLS and PPML cases, one possibility is to filter in the same summary functions.

### OLS solution for the "distance puzzle"

The gravity specification, which includes $\pi_{i,t} + \chi_{i,t}$, means that we need to do something very similar to what we did in the last section.

With the data from above, the model specification is straightforward.

```{r ch1_app_2_ols_1}
fit_ols_distance_puzzle <- felm(
  log_trade ~ log_dist_1986 + log_dist_1990 + log_dist_1994 +
    log_dist_1998 + log_dist_2002 + log_dist_2006 + cntg + lang + clny | exp_year +
    imp_year | pair_id,
  data = filter(ch1_application2, importer != exporter, trade > 0)
)

fit_ols_distance_puzzle
```

For the inference, we need to use the Delta method on the estimated coefficients.

```{r ch1_app_2_ols_2}
beta_log_dist <- grep("log_dist", rownames(fit_ols_distance_puzzle$coef_table), value = TRUE)
beta_log_dist <- c(min(beta_log_dist), max(beta_log_dist))

# change = 100 * (beta2 - beta1) / beta1
betas <- fit_ols_distance_puzzle$coef_table[, 1][beta_log_dist]
beta_pct_chg <- as.numeric(100 * (betas[2] - betas[1]) / betas[1])

beta_vcov_cluster <- fit_ols_distance_puzzle$vcov[
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ols_distance_puzzle$vcov))),
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ols_distance_puzzle$vcov)))
]

beta_std_err <- deltamethod(
  ~ 100 * (x2 - x1) / x1,
  c(betas[1], betas[2]), beta_vcov_cluster
)

beta_tstat <- beta_pct_chg / beta_std_err

beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "pct_chg_log_dist" = beta_pct_chg,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### PPML solution for the "distance puzzle"

This model is very similar to the one specified in the PPML section from the last section. We can directly fit the model.

```{r ch1_app_2_ppml_1}
fit_ppml_distance_puzzle <- fepoisson(
  trade ~ log_dist_1986 + log_dist_1990 + log_dist_1994 +
    log_dist_1998 + log_dist_2002 + log_dist_2006 + cntg + lang + clny |
    exp_year + imp_year | pair_id,
  data = filter(ch1_application2, importer != exporter)
)

fit_ppml_distance_puzzle
```

For the inference, we need to use the Delta method on the estimated coefficients as we did in the OLS case.

```{r ch1_app_2_ppml_2}
beta_log_dist <- grep("log_dist", rownames(fit_ppml_distance_puzzle$coef_table), value = TRUE)
beta_log_dist <- c(min(beta_log_dist), max(beta_log_dist))

# change = 100 * (beta2 - beta1) / beta1
betas <- fit_ppml_distance_puzzle$coef_table[, 1][beta_log_dist]
beta_pct_chg <- as.numeric(100 * (betas[2] - betas[1]) / betas[1])

beta_vcov_cluster <- fit_ppml_distance_puzzle$vcov[
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_distance_puzzle$vcov))),
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_distance_puzzle$vcov)))
]

beta_std_err <- deltamethod(
  ~ 100 * (x2 - x1) / x1,
  c(betas[1], betas[2]), beta_vcov_cluster
)

beta_tstat <- beta_pct_chg / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "pct_chg_log_dist" = beta_pct_chg,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### Internal distance solution for the "distance puzzle"

This model requires us to add the internal distance variable to the PPML model and not filter the rows where the exporter and the importer are the same.

```{r ch1_app_2_intra_1}
fit_ppml_intra_distance_puzzle <- fepoisson(
  trade ~ log_dist_1986 + log_dist_1990 + log_dist_1994 +
    log_dist_1998 + log_dist_2002 + log_dist_2006 + cntg + lang + clny +
    log_dist_intra | exp_year + imp_year | pair_id,
  data = ch1_application2
)

fit_ppml_intra_distance_puzzle
```

For the inference, we need to use the Delta method on the estimated coefficients as we did in the OLS case (we need the
numbers for the regular expression).

```{r ch1_app_2_intra_2}
beta_log_dist <- grep("log_dist_[0-9]{4}", rownames(fit_ppml_intra_distance_puzzle$coef_table), value = TRUE)
beta_log_dist <- c(min(beta_log_dist), max(beta_log_dist))

# change = 100 * (beta2 - beta1) / beta1
betas <- fit_ppml_intra_distance_puzzle$coef_table[, 1][beta_log_dist]
beta_pct_chg <- as.numeric(100 * (betas[2] - betas[1]) / betas[1])

beta_vcov_cluster <- fit_ppml_intra_distance_puzzle$vcov[
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_intra_distance_puzzle$vcov))),
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_intra_distance_puzzle$vcov)))
]

beta_std_err <- deltamethod(
  ~ 100 * (x2 - x1) / x1,
  c(betas[1], betas[2]), beta_vcov_cluster
)

beta_tstat <- beta_pct_chg / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "pct_chg_log_dist" = beta_pct_chg,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### Internal distance and home bias solution for the "distance puzzle"

This model requires us to add the same country variable to the internal distance model and repeat the rest of the steps from the last section.

```{r ch1_app_2_home_1}
fit_ppml_home_distance_puzzle <- fepoisson(
  trade ~ log_dist_1986 + log_dist_1990 + log_dist_1994 +
    log_dist_1998 + log_dist_2002 + log_dist_2006 + cntg + lang + clny +
    log_dist_intra + smctry | exp_year + imp_year | pair_id,
  data = ch1_application2
)

fit_ppml_home_distance_puzzle
```

For the inference, we need to use the Delta method on the estimated coefficients as we did in the OLS case (we need the
numbers for the regular expression).

```{r ch1_app_2_home_2}
beta_log_dist <- grep("log_dist_[0-9]{4}", rownames(fit_ppml_home_distance_puzzle$coef_table), value = TRUE)
beta_log_dist <- c(min(beta_log_dist), max(beta_log_dist))

# change = 100 * (beta2 - beta1) / beta1
betas <- fit_ppml_home_distance_puzzle$coef_table[, 1][beta_log_dist]
beta_pct_chg <- as.numeric(100 * (betas[2] - betas[1]) / betas[1])

beta_vcov_cluster <- fit_ppml_home_distance_puzzle$vcov[
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_home_distance_puzzle$vcov))),
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_ppml_home_distance_puzzle$vcov)))
]

beta_std_err <- deltamethod(
  ~ 100 * (x2 - x1) / x1,
  c(betas[1], betas[2]), beta_vcov_cluster
)

beta_tstat <- beta_pct_chg / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "pct_chg_log_dist" = beta_pct_chg,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### Fixed effects solution for the "distance puzzle"

This model requires us to remove the internal distance and same country variables from the last model and include the internal pair variable to account for the intra-national fixed effects.

```{r ch1_app_2_fe_1}
fit_fe_distance_puzzle <- fepoisson(
  trade ~ log_dist_1986 + log_dist_1990 + log_dist_1994 +
    log_dist_1998 + log_dist_2002 + log_dist_2006 + cntg + lang + clny +
    intra_pair | exp_year + imp_year | pair_id,
  data = ch1_application2
)

fit_fe_distance_puzzle
```

For the inference, we need to use the Delta method on the estimated coefficients as we did in the OLS case.

```{r ch1_app_2_fe_2}
beta_log_dist <- grep("log_dist_[0-9]{4}", rownames(fit_fe_distance_puzzle$coef_table), value = TRUE)
beta_log_dist <- c(min(beta_log_dist), max(beta_log_dist))

# change = 100 * (beta2 - beta1) / beta1
betas <- fit_fe_distance_puzzle$coef_table[, 1][beta_log_dist]
beta_pct_chg <- as.numeric(100 * (betas[2] - betas[1]) / betas[1])

beta_vcov_cluster <- fit_fe_distance_puzzle$vcov[
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_fe_distance_puzzle$vcov))),
  which(grepl(paste(beta_log_dist, collapse = "|"), rownames(fit_fe_distance_puzzle$vcov)))
]

beta_std_err <- deltamethod(
  ~ 100 * (x2 - x1) / x1,
  c(betas[1], betas[2]), beta_vcov_cluster
)

beta_tstat <- beta_pct_chg / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "pct_chg_log_dist" = beta_pct_chg,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

## Regional trade agreements effects

### Preparing the data

This model specification includes gravity covariates, including importer-time and exporter-time fixed effects, as in the equation

$$
\begin{align}
X_{ij,t} =& \:\exp\left[\pi_{i,t} + \chi_{i,t} + \beta_1 \log(DIST)_{i,j} + \beta_2 CNTG_{i,j} + \beta_3 LANG_{i,j} +\right.\\
\text{ }& \:\left.\beta_4 CLNY_{i,j} + \beta_5 RTA_{ij,t}\right] \times \varepsilon_{ij,t}.
\end{align}
$$

In comparison to the previous examples, we need to create additional variables to include fixed effects that account for the observations where the exporter and the importer are the same. These variables are internal border, internal dyad and internal borders for different years.

The direct way of obtaining the desired variables is similar to what we did in the previous sections.

```{r ch1_app_3_data_1}
ch1_application3 <- agtpa_applications %>%
  filter(year %in% seq(1986, 2006, 4)) %>%
  mutate(
    exp_year = paste0(exporter, year),
    imp_year = paste0(importer, year),
    year = paste0("intl_border_", year),
    log_trade = log(trade),
    log_dist = log(dist),
    intl_brdr = ifelse(exporter == importer, pair_id, "inter"),
    intl_brdr_2 = ifelse(exporter == importer, 0, 1),
    pair_id_2 = ifelse(exporter == importer, "0-intra", pair_id)
  ) %>%
  pivot_wider(names_from = year, values_from = intl_brdr_2, values_fill = 0)
```

Notice that we used "0-intra" and not just "intra" because the rest of the observations in the internal dyads are numbers 1, ..., N, and R internals shall consider "0-intra" as the reference factor for being the first item when it orders the unique observations alphabetically. Also, observe the order of the resulting table, the pivoting of the table will put "0-intra" as the first row for the first exporter-importer dyad. This makes the difference between the expected or other behaviours in the next chapter.

In addition, we need to create the variable containing the trade sum to filter the cases where the sum by dyad is zero.

```{r ch1_app_3_data_2}
ch1_application3 <- ch1_application3 %>%
  group_by(pair_id) %>%
  mutate(sum_trade = sum(trade)) %>%
  ungroup()
```

### OLS standard RTA estimates with international trade only

The gravity specification, which includes $\pi_{i,t} + \chi_{i,t}$, means that we need to do something very similar to what we did in the last section.

With the data from above, the model specification is straightforward.

```{r ch1_app_3_ols_1}
fit_ols_rta <- felm(
  log_trade ~ log_dist + cntg + lang + clny + rta | exp_year + imp_year | pair_id,
  data = filter(ch1_application3, trade > 0, importer != exporter)
)

fit_ols_rta
```

### PPML standard RTA estimates with international trade only

The model specification is very similar to OLS, and we only need to change the method specified in the function.

```{r ch1_app_3_ppml_1}
fit_ppml_rta <- fepoisson(
  trade ~ log_dist + cntg + lang + clny + rta | exp_year + imp_year | pair_id,
  data = filter(ch1_application3, importer != exporter)
)

fit_ppml_rta
```

### Addressing potential domestic trade diversion

The model specification is quite the same as PPML. We only need to add the international border variable but use the entire dataset instead of removing rows where the importer and the exporter are the same.

```{r ch1_app_3_intra_1}
fit_intra_rta <- fepoisson(
  trade ~ log_dist + cntg + lang + clny + rta | exp_year + imp_year +
    intl_brdr | pair_id,
  data = ch1_application3
)

fit_intra_rta
```

### Addressing potential endogeneity of RTAs

The model specification includes the RTA variable and the exporter-time, importer-time and internal dyad fixed effects to account for domestic trade.

```{r ch1_app_3_endg_1}
fit_endg_rta <- fepoisson(
  trade ~ rta | exp_year + imp_year + pair_id_2 | pair_id,
  data = filter(ch1_application3, sum_trade > 0)
)

fit_endg_rta
```

### Testing for potential "reverse causality" between trade and RTAs

We need to modify the previous model to include the forward lagged RTA variable (by four years) and consider where the trade sum is larger than zero.

```{r ch1_app_3_lead_1}
fit_lead_rta <- fepoisson(
  trade ~ rta + rta_lead4 | exp_year + imp_year + pair_id_2 | pair_id,
  data = filter(ch1_application3, sum_trade > 0)
)

fit_lead_rta

beta_rta <- fit_lead_rta$coef_table[, 1]
beta_sum <- sum(beta_rta)

beta_form <- paste(paste0("x", seq_along(beta_rta)), collapse = "+")
beta_form <- paste0("~", beta_form)

beta_std_err <- deltamethod(as.formula(beta_form), beta_rta, fit_lead_rta$vcov)
beta_tstat <- beta_sum / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "sum_coef_rta" = beta_sum,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### Addressing potential non-linear and phasing-in effects of RTAs

Instead of future-lagged RTA variables, as in the previous model, we modify the previous model and include the RTA backwards lagged variables instead.

```{r ch1_app_3_phsng_1}
fit_phsng_rta <- fepoisson(
  trade ~ rta + rta_lag4 + rta_lag8 + rta_lag12 | exp_year + imp_year + pair_id_2 | pair_id,
  data = filter(ch1_application3, sum_trade > 0)
)

fit_phsng_rta

beta_rta <- fit_phsng_rta$coef_table[, 1]
beta_sum <- sum(beta_rta)

beta_form <- paste(paste0("x", seq_along(beta_rta)), collapse = "+")
beta_form <- paste0("~", beta_form)

beta_std_err <- deltamethod(as.formula(beta_form), beta_rta, fit_phsng_rta$vcov)
beta_tstat <- beta_sum / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "sum_coef_rta" = beta_sum,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

### Addressing globalization effects

In addition to the previous model, we include the international borders on different years besides the lagged RTAs.

```{r ch1_app_3_glbzn_1}
fit_glbzn_rta <- fepoisson(
  trade ~ rta + rta_lag4 + rta_lag8 + rta_lag12 + intl_border_1986 +
    intl_border_1990 + intl_border_1994 + intl_border_1998 + intl_border_2002 |
    exp_year + imp_year + pair_id_2 | pair_id,
  data = filter(ch1_application3, sum_trade > 0)
)

fit_glbzn_rta

beta_rta <- fit_glbzn_rta$coef_table[, 1][grep("rta", rownames(fit_glbzn_rta$coef_table))]
beta_sum <- sum(beta_rta)

beta_form <- paste(paste0("x", seq_along(beta_rta)), collapse = "+")
beta_form <- paste0("~", beta_form)

beta_std_err <- deltamethod(as.formula(beta_form), beta_rta, fit_glbzn_rta$vcov[names(beta_rta), names(beta_rta)])
beta_tstat <- beta_sum / beta_std_err
beta_pval <- pnorm(-abs(beta_tstat)) + (1 - pnorm(abs(beta_tstat)))

round(c(
  "sum_coef_rta" = beta_sum,
  "std_err" = beta_std_err,
  "p-value" = beta_pval
), 4)
```

## References

[["data.html", "Chapter 4 Appendix: Importing the original datasets 4.1 Software 4.2 Downloading the original datasets 4.3 Converting the original datasets", " Chapter 4 Appendix: Importing the original datasets 4.1 Software I followed the standards and conventions from the Tidyverse, and I converted all the original datasets in Stata with this software: R version 3.6.3 (2020-02-29) Platform: x86_64-pc-linux-gnu (64-bit) locale: LC_CTYPE=en_US.UTF-8, LC_NUMERIC=C, LC_TIME=es_CL.UTF-8, LC_COLLATE=en_US.UTF-8, LC_MONETARY=es_CL.UTF-8, LC_MESSAGES=en_US.UTF-8, LC_PAPER=es_CL.UTF-8, LC_NAME=C, LC_ADDRESS=C, LC_TELEPHONE=C, LC_MEASUREMENT=es_CL.UTF-8 and LC_IDENTIFICATION=C attached base packages: stats, graphics, grDevices, utils, datasets, methods and base other attached packages: purrr(v.0.3.4), janitor(v.2.0.1), stringr(v.1.4.0), haven(v.2.3.1), ggplot2(v.3.3.2), duckdb(v.0.2.1-2), DBI(v.1.1.0), msm(v.1.6.8), broom(v.0.7.1), lmtest(v.0.9-38), zoo(v.1.8-8), sandwich(v.3.0-0), multiwayvcov(v.1.2.3), tidyr(v.1.1.2), dplyr(v.1.0.2) and yotover(v.0.0.0.9000) loaded via a namespace (and not attached): Rcpp(v.1.0.5), lubridate(v.1.7.9), mvtnorm(v.1.1-1), lattice(v.0.20-41), assertthat(v.0.2.1), digest(v.0.6.26), utf8(v.1.1.4), R6(v.2.4.1), backports(v.1.1.10), evaluate(v.0.14), httr(v.1.4.2), pillar(v.1.4.6), rlang(v.0.4.8), data.table(v.1.13.0), rstudioapi(v.0.11), R.utils(v.2.10.1), R.oo(v.1.24.0), Matrix(v.1.2-18), rmarkdown(v.2.4), labeling(v.0.3), splines(v.3.6.3), servr(v.0.20), pander(v.0.6.3), munsell(v.0.5.0), httpuv(v.1.5.4), compiler(v.3.6.3), xfun(v.0.18), pkgconfig(v.2.0.3), htmltools(v.0.5.0), tidyselect(v.1.1.0), tibble(v.3.0.4), expm(v.0.999-5), bookdown(v.0.21), codetools(v.0.2-16), fansi(v.0.4.1), later(v.1.1.0.1), crayon(v.1.3.4), withr(v.2.3.0), R.methodsS3(v.1.8.1), rappdirs(v.0.3.1), grid(v.3.6.3), jsonlite(v.1.7.1), gtable(v.0.3.0), lifecycle(v.0.2.0), magrittr(v.1.5), scales(v.1.1.1), cli(v.2.1.0), stringi(v.1.5.3), farver(v.2.0.3), promises(v.1.1.1), snakecase(v.0.11.0), ellipsis(v.0.3.1), generics(v.0.0.2), vctrs(v.0.3.4), boot(v.1.3-25), tools(v.3.6.3), forcats(v.0.5.0), glue(v.1.4.2), hms(v.0.5.3), parallel(v.3.6.3), survival(v.3.1-12), yaml(v.2.2.1), colorspace(v.1.4-1) and knitr(v.1.30) 4.2 Downloading the original datasets appfiles_url &lt;- &quot;https://vi.unctad.org/tpa/web/zips/vol2/Advanced%20Guide%20to%20TPA.zip&quot; appfiles_zip &lt;- &quot;00-application-files.zip&quot; appfiles_dir &lt;- &quot;00-application-files&quot; if (!file.exists(appfiles_zip)) { download.file(appfiles_url, appfiles_zip) } if (!dir.exists(appfiles_dir)) { unzip(appfiles_zip) file.rename(&quot;Advanced Guide to TPA&quot;, appfiles_dir) } 4.3 Converting the original datasets This code chunk can be a bit obscure. It is only shown to make all of my steps transparent. # these packages are only used to import the data library(haven) library(stringr) library(janitor) library(purrr) try(dir.create(&quot;data-tsv&quot;, showWarnings = F)) dta_files &lt;- list.files(&quot;00-application-files&quot;, pattern = &quot;dta&quot;, full.names = TRUE, recursive = TRUE) read_and_clean &lt;- function(finp) { message(finp) fout &lt;- finp %&gt;% str_replace(appfiles_dir, &quot;&quot;) %&gt;% str_replace(&quot;Chapter&quot;, &quot;ch&quot;) %&gt;% str_replace_all(&quot;Chapter[0-9]|\\\\.dta&quot;, &quot;&quot;) fout &lt;- fout %&gt;% str_replace_all(&quot;(/)&quot;, &quot;_&quot;) %&gt;% make_clean_names() long_names &lt;- c( &quot;datasets_&quot;, &quot;applications_&quot;, &quot;exercises_&quot;, &quot;1_trade_without_border_results_1&quot;, &quot;2_rt_as_effects_results_2_&quot; ) fout &lt;- fout %&gt;% str_replace_all(paste(long_names, collapse = &quot;|&quot;), &quot;&quot;) fout &lt;- str_replace(fout, &quot;_([0-9])_|__&quot;, &quot;_&quot;) fout2 &lt;- sprintf(&quot;data-tsv/%s.tsv&quot;, fout) if (!file.exists(fout2)) { d &lt;- read_dta(finp) %&gt;% clean_names() data.table::fwrite(d, fout2, sep = &quot;\\t&quot;) } } map(dta_files, read_and_clean) "]]
